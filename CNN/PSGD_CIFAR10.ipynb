{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PSGD_CIFAR10.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Pn7E8tXofBdm"},"source":["#Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaZdyOqH8ta1","executionInfo":{"status":"ok","timestamp":1619398439102,"user_tz":-300,"elapsed":3475,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"9055ea66-82c0-4c3e-ecdc-51b0bdfb46f2"},"source":["!pip install pkbar"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pkbar in /usr/local/lib/python3.7/dist-packages (0.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pkbar) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F0hq8_ykmK2J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619398439931,"user_tz":-300,"elapsed":4289,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"f477f92a-bfcd-44b7-a6c5-4882e8fd40a1"},"source":["from google.colab import drive\n","from google.colab import files\n","import sys\n","import time\n","\n","drive.mount('/content/gdrive/', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\"\n","base_dir = root_dir + 'Colab Notebooks/MS Thesis/PSGD Paper/'\n","results_dir = base_dir + 'CNN/results/'\n","logs_dir = base_dir + 'log'\n","sys.path.append(base_dir)\n","import preconditioned_stochastic_gradient_descent as psgd \n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aEZtit9cjlMG","executionInfo":{"status":"ok","timestamp":1619398440527,"user_tz":-300,"elapsed":4874,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["import matplotlib.pyplot as plt\n","import torch\n","from torch.autograd import grad\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import numpy as np\n","import time\n","import tqdm\n","import pkbar\n","import math\n","\n","from tabulate import tabulate\n","import scipy.io\n","from sklearn import metrics\n","import plotly.express as px\n","from torchsummary import summary\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QKooB49HfKzR"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"roPf15eMfNuJ","executionInfo":{"status":"ok","timestamp":1619398440528,"user_tz":-300,"elapsed":4867,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["def plot_loss_metrics(xaxis,yaxis,title, x_label,y_label):\n"," \n","  fig = go.Figure()\n","  i = 0\n","  if(xaxis != None):\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(x = xaxis[opt], y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","  else:\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","\n","  fig.update_layout(title=title, xaxis_title=x_label, yaxis_title=y_label, yaxis_type=\"log\")\n","  fig.show()\n","  fig.write_html(results_dir + title + \".html\")\n","\n","def plot_acc_metrics(xaxis,yaxis,title, x_label,y_label):\n"," \n","  fig = go.Figure()\n","  i = 0\n","  if(xaxis != None):\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(x = xaxis[opt], y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","  else:\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","\n","  fig.update_layout(title=title, xaxis_title=x_label, yaxis_title=y_label, yaxis=dict(range=[0.97, 1]))\n","  fig.show()\n","  fig.write_html(results_dir + title + \".html\")\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ejKz-9nfUoy","executionInfo":{"status":"ok","timestamp":1619398440529,"user_tz":-300,"elapsed":4860,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["np.random.seed(0)\n","\n","# Parameter Settings\n","BATCH_SIZE = 64\n","test_BATCH_SIZE = 1000\n","EPOCHS = 20\n","GAP = 100"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t71vTNyumHao"},"source":["# Data Download"]},{"cell_type":"code","metadata":{"id":"LyioOEA_kdvB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619398442162,"user_tz":-300,"elapsed":6482,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"e96d20ca-b194-42aa-b56d-a833efee757e"},"source":["train_loader = torch.utils.data.DataLoader(\n","        datasets.CIFAR10('./data', train=True, download=True,           \n","                       transform=transforms.Compose([                       \n","                               transforms.ToTensor()])),    \n","                        batch_size=BATCH_SIZE, shuffle=True, num_workers = 4, pin_memory = True)\n","test_loader = torch.utils.data.DataLoader(    \n","        datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n","                       transforms.ToTensor()])),    \n","                        batch_size=test_BATCH_SIZE, shuffle=True, num_workers=4, pin_memory = True)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LAMhwYaRmbIF","executionInfo":{"status":"ok","timestamp":1619398442164,"user_tz":-300,"elapsed":6473,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["n_batches = np.ceil(len(train_loader.dataset)/BATCH_SIZE)\n","n_test_batches = np.ceil(len(test_loader.dataset)/test_BATCH_SIZE)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAJdx1Ga6xFX","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1619398442166,"user_tz":-300,"elapsed":6464,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"204e6fc3-5faa-49ae-ceec-ac0b602f0c7b"},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n","    print(\"Running on the GPU\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Running on the CPU\")\n","torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Running on the GPU\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"O55VB__slpJx"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"2N_7RpDVlbZE","executionInfo":{"status":"ok","timestamp":1619398442168,"user_tz":-300,"elapsed":6454,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["\"\"\"input image size for the original myModel is 32x32, here is 28x28\"\"\"\n","torch.manual_seed(1)\n","torch.cuda.manual_seed_all(1)\n","num_fs = [32, 64, 128, 128, 256, 256]\n","den_fs = [4096, 1024, 512]\n","nClasses = 10\n","def initialize_weights():\n","    W1 = torch.nn.init.xavier_uniform_((0.1*torch.randn(3*3*3+1,  num_fs[0])).clone().detach().requires_grad_(True)).to(device)\n","    W2 = torch.nn.init.xavier_uniform_((0.1*torch.randn(num_fs[0]*3*3+1, num_fs[1])).clone().detach().requires_grad_(True)).to(device)\n","    W3 = torch.nn.init.xavier_uniform_((0.1*torch.randn(num_fs[1]*3*3+1, num_fs[2])).clone().detach().requires_grad_(True)).to(device)\n","    W4 = torch.nn.init.xavier_uniform_((0.1*torch.randn(num_fs[2]*3*3+1, num_fs[3])).clone().detach().requires_grad_(True)).to(device)\n","    W5 = torch.nn.init.xavier_uniform_((0.1*torch.randn(num_fs[3]*3*3+1, num_fs[4])).clone().detach().requires_grad_(True)).to(device)\n","    W6 = torch.nn.init.xavier_uniform_((0.1*torch.randn(num_fs[4]*3*3+1, num_fs[5])).clone().detach().requires_grad_(True)).to(device)\n","\n","    W7 = torch.nn.init.xavier_uniform_((0.1*torch.randn(den_fs[0]+1, den_fs[1])).clone().detach().requires_grad_(True)).to(device)\n","    W8 = torch.nn.init.xavier_uniform_((0.1*torch.randn(den_fs[1]+1, den_fs[2])).clone().detach().requires_grad_(True)).to(device)\n","    W9 = torch.nn.init.xavier_uniform_((0.1*torch.randn(den_fs[2]+1, nClasses)).clone().detach().requires_grad_(True)).to(device)\n","    \n","    Ws = [W1, W2, W3, W4, W5, W6, W7, W8, W9]\n","    return Ws\n","\n","def myModel(x): \n","    p = 1\n","    W1, W2, W3, W4, W5, W6, W7, W8, W9 = Ws\n","    x = F.relu(F.conv2d(x, W1[:-1].view(num_fs[0],3,3,3), bias=W1[-1], padding = p))\n","    x = F.relu(F.conv2d(x, W2[:-1].view(num_fs[1],num_fs[0],3,3), bias=W2[-1], padding = p))\n","    x = F.max_pool2d(x, 2)\n","    \n","    x = F.relu(F.conv2d(x, W3[:-1].view(num_fs[2],num_fs[1],3,3), bias=W3[-1], padding = p))\n","    x = F.relu(F.conv2d(x, W4[:-1].view(num_fs[3],num_fs[2],3,3), bias=W4[-1], padding = p))\n","    x = F.max_pool2d(x, 2)\n","    \n","    x = F.relu(F.conv2d(x, W5[:-1].view(num_fs[4],num_fs[3],3,3), bias=W5[-1], padding = p))\n","    x = F.relu(F.conv2d(x, W6[:-1].view(num_fs[5],num_fs[4],3,3), bias=W6[-1], padding = p))\n","    x = F.max_pool2d(x, 2)\n","    \n","    x = F.relu(x.view(-1,den_fs[0]).mm(W7[:-1]) + W7[-1])\n","    x = F.relu(x.mm(W8[:-1]) + W8[-1])\n","    y = x.mm(W9[:-1]) + W9[-1]\n","    \n","    return F.log_softmax(y, dim=1)\n","\n","# Ws = initialize_weights()\n","# myModel(torch.zeros(3,3,32,32).to(device))"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1hOFi1DHlx2Q"},"source":["# Loss Function"]},{"cell_type":"code","metadata":{"id":"ttaD9mDElrR1","executionInfo":{"status":"ok","timestamp":1619398442169,"user_tz":-300,"elapsed":6447,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["def train_loss(data, target):\n","    y = myModel(data)\n","    loss = F.nll_loss(y, target)\n","    # loss = F.cross_entropy(y, target)\n","    _, max_indices = torch.max(y, dim = 1)\n","    accuracy = (max_indices == target).sum(dtype=torch.float32)/max_indices.size(0)\n","    return loss, accuracy\n","\n","def test_loss():\n","    loss = 0\n","    accuracy = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            y = myModel(data)\n","            loss += F.nll_loss(y, target)\n","            _, pred = torch.max(y, dim=1)\n","            accuracy += (pred == target).sum(dtype=torch.float32)/pred.size(0)\n","    return loss.item()/n_test_batches, accuracy.item()/n_test_batches\n","\n","def update_lambda(loss1, loss2, M, lambd, omega):\n","    \n","    r = abs(loss2 - loss1)/(M)\n","    # print(r, M, lambd)\n","    if r > 3/4:\n","      lambd = lambd*omega\n","    elif r < 1/4:\n","      lambd = lambd / omega\n","    return lambd\n","    \n","def save_start_condition(trainlosslist, testlosslist,trainacclist, testacclist, timelist):\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      data, target = data.to(device), target.to(device)\n","      loss, accuracy = train_loss(data, target)\n","      trainloss += loss\n","      trainacc += accuracy\n","      \n","  \n","    timelist.append(0)\n","\n","    testloss, testacc = test_loss()\n","\n","    trainlosslist.append(trainloss.item()/n_batches)\n","    trainacclist.append(trainacc.item()/n_batches)\n","    testlosslist.append(testloss)\n","    testacclist.append(testacc)\n","    print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    .format(0, trainlosslist[-1], testlosslist[-1], trainacclist[-1], testacclist[-1],np.sum(timelist)))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":836},"id":"kfxrPzQVhT6Q","executionInfo":{"status":"error","timestamp":1619398449930,"user_tz":-300,"elapsed":14199,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"23b66c49-b5a9-4355-db11-1328dad0f605"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","with torch.no_grad():\n","    save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","        if n % 10 == 0:\n","            \n","            v = [torch.randn(W.shape).to(device) for W in Ws]\n","            Ws = [w + v for (w, v) in zip(Ws, v)]\n","            loss_1, _ = train_loss(data, target)\n","            grads2 = grad(loss_1, Ws)\n","            Hv = [g2 - g for (g, g2) in zip(grads, grads2)]\n","            Ws = [w - v for (w, v) in zip(Ws, v)]\n","            # Hv = grad(grads, Ws, v)\n","            with torch.no_grad():\n","                Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","    \n","  \n","        with torch.no_grad():          \n","            pre_grads = [psgd.precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    \n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'Kron.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n","Exception in thread Thread-12:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n","    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n","    return _ForkingPickler.loads(res)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n","    fd = df.detach()\n","  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n","    with _resource_sharer.get_connection(self._id) as conn:\n","  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n","    c = Client(address, authkey=process.current_process().authkey)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n","    c = SocketClient(address)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n","    s.connect(address)\n","FileNotFoundError: [Errno 2] No such file or directory\n","\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-26f3b4ddb0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msave_start_condition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestAcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-a2b806c67877>\u001b[0m in \u001b[0;36msave_start_condition\u001b[0;34m(trainlosslist, testlosslist, trainacclist, testacclist, timelist)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrainloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtrainacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"w5nub-2OIB1v"},"source":["# ALL TEST"]},{"cell_type":"markdown","metadata":{"id":"KHHRjmBv5nGy"},"source":["## SGD"]},{"cell_type":"code","metadata":{"id":"6-Kz6zZw5osv","executionInfo":{"status":"aborted","timestamp":1619398449920,"user_tz":-300,"elapsed":14175,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","with torch.no_grad():\n","    save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","        \n","        with torch.no_grad():\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*grads[i]\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    \n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'sgd.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dYV3Ro1nl9-w"},"source":["## Adam"]},{"cell_type":"code","metadata":{"id":"ShkQySPkl0jM","executionInfo":{"status":"aborted","timestamp":1619398449922,"user_tz":-300,"elapsed":14169,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","\n","m0 = [torch.zeros(W.shape).to(device) for W in Ws]\n","v0 = [torch.zeros(W.shape).to(device) for W in Ws]\n","step_size = 0.001\n","cnt = 0\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","with torch.no_grad():\n","    save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","for epoch in range(EPOCHS):\n","    n = 0\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws)#, create_graph=True)\n","        trainloss += loss\n","        trainacc += accuracy\n","        \n","\n","        with torch.no_grad():\n","            lmbd = min(cnt/(cnt+1), 0.9)\n","            m0 = [lmbd*old + (1.0-lmbd)*new for (old, new) in zip(m0, grads)]\n","            lmbd = min(cnt/(cnt+1), 0.999)\n","            v0 = [lmbd*old + (1.0-lmbd)*new*new for (old, new) in zip(v0, grads)]\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_size*(m0[i]/torch.sqrt(v0[i] + 1e-8))\n","            cnt = cnt + 1\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1    \n","        \n","    t1 = time.time() - t0\n","    times.append(t1)\n","\n","    testloss, testacc = test_loss()\n","\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    # .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'adam.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8AoYYDPCIMkn"},"source":["## Full Kronecker"]},{"cell_type":"code","metadata":{"id":"lRcCtC_omg8l","executionInfo":{"status":"aborted","timestamp":1619398449923,"user_tz":-300,"elapsed":14157,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","with torch.no_grad():\n","    save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","\n","        if n % 100 == 0:\n","            v = [torch.randn(W.shape).to(device) for W in Ws]\n","            Ws = [w + v for (w, v) in zip(Ws, v)]\n","            loss_1, _ = train_loss(data, target)\n","            \n","            Hv = grad(grads, Ws, v)\n","            with torch.no_grad():\n","                Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","        with torch.no_grad():\n","            \n","            pre_grads = [psgd.precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    \n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'Kron.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3XDQPC9p5vgk"},"source":["## Damped Kronecker"]},{"cell_type":"code","metadata":{"id":"m7A2qd5XHXzL","executionInfo":{"status":"aborted","timestamp":1619398449923,"user_tz":-300,"elapsed":14149,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["_tiny = 1.2e-38 \n"," # pi = (torch.trace(Ql)*Qr.shape[0])/(torch.trace(Qr)*Ql.shape[0])\n","    # \n","\n","    \n","def precond_grad_kron(Ql, Qr, Grad):\n","    P1 = Ql.t().mm(Ql)\n","    P2 = Qr.t().mm(Qr)\n","    pi = (torch.trace(P1)*P2.shape[0])/(torch.trace(P2)*P1.shape[0])\n","    IL = torch.ones(P1.shape[0]).to(device)\n","    IR = (torch.ones(P2.shape[0])).to(device)\n","    P1 = P1 + torch.diag(torch.sqrt((pi)*(eta + lambd**0.5))*IL)\n","    P2 = P2 + torch.diag(torch.sqrt((1/pi)*(eta + lambd**0.5))*IR)\n","\n","    return P1.mm(Grad).mm(P2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L07W8H555y9S","executionInfo":{"status":"aborted","timestamp":1619398449924,"user_tz":-300,"elapsed":14148,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","with torch.no_grad():\n","    save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","lambd = 1\n","update_after = 100\n","omega = (19/20)**update_after\n","\n","eta = 1e-5\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    \n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","\n","        if n % 10 == 0:\n","            v = [torch.randn(W.shape).to(device) for W in Ws]\n","            Ws = [w + v for (w, v) in zip(Ws, v)]\n","            loss_1, _ = train_loss(data, target)\n","            grads2 = grad(loss_1, Ws)\n","            Hv = [g2 - g for (g, g2) in zip(grads, grads2)]\n","            Ws = [w - v for (w, v) in zip(Ws, v)]\n","            # Hv = grad(grads, Ws, v)\n","            with torch.no_grad():\n","                Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","        \n","        with torch.no_grad():\n","            pre_grads = [precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","\n","            if n % update_after == 0 and lambd > 1e-10:\n","                M = min([0.5*torch.dot(g.view(-1,), step_size*pg.view(-1,)) for (g, pg) in zip(grads, pre_grads)])\n","                loss2 = F.nll_loss(myModel(data), target)\n","                loss1 = loss\n","                lambd = update_lambda(loss1, loss2, M,  lambd, omega)\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","\n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'Kron_damped.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oV8NJocOrzsM","executionInfo":{"status":"ok","timestamp":1619398944070,"user_tz":-300,"elapsed":6379,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":[" loss, accuracy = train_loss(data, target)\n"," grads = grad(loss, Ws, retain_graph = True)\n"," Ws = [w + v for (w, v) in zip(Ws, v)]\n"," grads2 = grad(loss, Ws, allow_unused=True)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"7kH9_1xXr7WV","executionInfo":{"status":"error","timestamp":1619398958476,"user_tz":-300,"elapsed":1001,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"d052bbab-6b3f-43aa-e7e4-51c9ecaeba68"},"source":["Hv = [g2 - g for (g, g2) in zip(grads, grads2)]"],"execution_count":26,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-f4b84891a64f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-26-f4b84891a64f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__rsub__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rdiv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: rsub() received an invalid combination of arguments - got (Tensor, NoneType), but expected one of:\n * (Tensor input, Tensor other, *, Number alpha)\n * (Tensor input, Number other, Number alpha)\n"]}]},{"cell_type":"markdown","metadata":{"id":"pzF0kQ3g7Bb0"},"source":["## MIXED"]},{"cell_type":"code","metadata":{"id":"OM3_pW06XRPM","colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"status":"error","timestamp":1619398618621,"user_tz":-300,"elapsed":147262,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"d1d03623-6a1c-4159-9812-49a431463577"},"source":["def precond_kron(Ql, Qr, Pl, Pr, beta1, beta2):\n","    P1 = Ql.t().mm(Ql)\n","    P2 = Qr.t().mm(Qr)\n","    pi = (torch.trace(P1)*P2.shape[0])/(torch.trace(P2)*P1.shape[0])\n","    IL = torch.ones(P1.shape[0]).to(device)\n","    IR = (torch.ones(P2.shape[0])).to(device)\n","    P1 = P1 + torch.diag(torch.sqrt((pi)*(eta + lambd**0.5))*IL)\n","    P2 = P2 + torch.diag(torch.sqrt((1/pi)*(eta + lambd**0.5))*IR)\n","\n","    Pl = beta1*Pl + beta2*P1 \n","    Pr = beta1*Pr + beta2*P2 \n","\n","    return [P1, P2, Pl, Pr]\n","\n","def precond_kron2(Ql, Qr, Pl, Pr, beta1, beta2):\n","    P1 = Ql.t().mm(Ql)\n","    P2 = Qr.t().mm(Qr)\n","    Pl = beta1*Pl + beta2*P1 \n","    Pr = beta1*Pr + beta2*P2 \n","    return [P1, P2, Pl, Pr]\n","\n","def precond_grad_kron2(Pl, Pr, Grad):\n","    return Pl.mm(Grad).mm(Pr)\n","\n","torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","Ps = [[0.1*torch.eye(W.shape[0]).to(device), 0.1*torch.eye(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","with torch.no_grad():\n","    save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","lambd = 1\n","update_after = 100\n","omega = (19/20)**update_after\n","eta = 1e-5\n","\n","beta1 = 0.7\n","beta2 = 0.3\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    n = 0\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    t0 = time.time()\n","   \n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","\n","        if n % 10 == 0:\n","            v = [torch.randn(W.shape).to(device) for W in Ws]\n","            Ws = [w + v for (w, v) in zip(Ws, v)]\n","            loss_1, _ = train_loss(data, target)\n","            grads2 = grad(loss_1, Ws)\n","            Hv = [g2 - g for (g, g2) in zip(grads, grads2)]\n","            Ws = [w - v for (w, v) in zip(Ws, v)]\n","            # Hv = grad(grads, Ws, v)\n","            with torch.no_grad():\n","                Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","\n","                Ps = [precond_kron(q[0], q[1], p[0], p[1], beta1, beta2) for (q, p) in zip(Qs, Ps)]\n","        with torch.no_grad():            \n","            pre_grads = [precond_grad_kron2(p[2], p[3], g) for (p, g) in zip(Ps, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","            if n % update_after == 0 and lambd > 1e-10:\n","                M = min([0.5*torch.dot(g.view(-1,), step_size*pg.view(-1,)) for (g, pg) in zip(grads, pre_grads)])\n","                loss2 = F.nll_loss(myModel(data), target)\n","                loss1 = loss\n","                lambd = update_lambda(loss1, loss2, M, lambd, omega)\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","\n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'mod_psgd.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.358653661235214; test loss: 2.358446502685547, train_accuracy: 0.09950447570332481, test_accuracy:0.10119999647140503, time: 0\n","Epoch: 1/20\n","782/782 [==============================] - 45s 57ms/step - loss: 1.5511 - acc: 0.4349 - val_loss: 1.3381 - val_acc: 0.5207\n","Epoch: 2/20\n","782/782 [==============================] - 45s 57ms/step - loss: 0.9141 - acc: 0.6767 - val_loss: 0.9208 - val_acc: 0.6748\n","Epoch: 3/20\n","782/782 [==============================] - 45s 57ms/step - loss: 0.6536 - acc: 0.7745 - val_loss: 0.8416 - val_acc: 0.7076\n","Epoch: 4/20\n"," 60/782 [=>............................] - ETA: 45s - loss: 0.5129 - acc: 0.8255"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-5372dc476468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mWs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mloss_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-5372dc476468>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mWs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mloss_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"VKqHDHWs7rPo"},"source":["# Comparison"]},{"cell_type":"code","metadata":{"id":"2sNOWNfay0sr","executionInfo":{"status":"aborted","timestamp":1619398449926,"user_tz":-300,"elapsed":14130,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["opts = ['sgd','adam','KFAC', 'shampoo','Kron','Kron_damped', 'mod_psgd', 'mod_psgd1']\n","\n","total_train_time = {}\n","opts_data = {}\n","times = {}\n","train_times = {}\n","test_times = {}\n","train_losses = {}\n","test_losses = {}\n","train_accs = {}\n","test_accs = {}\n","\n","\n","for opt in opts:\n","\topts_data[opt] = scipy.io.loadmat(results_dir+opt+'.mat')\t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gIYMFyL-C8d","executionInfo":{"status":"aborted","timestamp":1619398449927,"user_tz":-300,"elapsed":14123,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["colors = ['#0000FF','#00FF00','#FF0000','#33F0FF','#FFA833','#000000','#33E0FF', '#FF33E6','#D433FF','#888A0B','#8A0B1E','#B498DF','#1B786D']\n","# colors = ['#0000FF','#00FF00','#FF0000','#33F0FF','#FFA833','#FFF933','#000000','#33E0FF','#FF33E6','#D433FF','#888A0B','#8A0B1E','#B498DF','#1B786D']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Rez_eVv8XdP","executionInfo":{"status":"aborted","timestamp":1619398449927,"user_tz":-300,"elapsed":14115,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["for opt in opts:\n","  # print(opt)\n","  data = opts_data[opt]\n","  times[opt] = data.get('Time')\n","  train_times[opt] = np.cumsum(times[opt])\n","  test_times[opt] = np.cumsum(times[opt])\n","  total_train_time[opt] = np.sum(times[opt])\n","  train_losses[opt] = data.get('TrainLoss').reshape(EPOCHS+1,)\n","  train_accs[opt] = data.get('TrainAccuracy').reshape(EPOCHS+1,)\n","  test_losses[opt] = data.get('TestLoss').reshape(EPOCHS+1,)\n","  test_accs[opt] = data.get('TestAccuracy').reshape(EPOCHS+1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOGytOmR8w3V","executionInfo":{"status":"aborted","timestamp":1619398449928,"user_tz":-300,"elapsed":14109,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["# plot train_losses vs Iterations\n","plot_loss_metrics(None,train_losses,'Train Loss vs EPOCHS', 'EPOCHS','Train Loss')\n","# plot test_losses vs Iterations\n","plot_loss_metrics(None,test_losses,'Test Loss vs EPOCHS', 'EPOCHS','Test Loss')\n","# # plot test_losses vs Iterations\n","plot_loss_metrics(train_times,train_losses,'Train Loss vs Time', 'Time','Train Loss')\n","# plot test_losses vs Iterations\n","plot_loss_metrics(test_times,test_losses,'Test Loss vs Time', 'Time','Test Loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1emXQ9-RLkxg","executionInfo":{"status":"aborted","timestamp":1619398449929,"user_tz":-300,"elapsed":14103,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":[""],"execution_count":null,"outputs":[]}]}