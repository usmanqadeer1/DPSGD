{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PSGD_FASHION_MNIST.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f59eb27e576b4722bfc8250a1d45aa08":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ed90d5c54eb545478a19ab6c6cda0a0c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1c7f8190cefe4394b05010bc4d894415","IPY_MODEL_efbc5601c0ca4272aa2c7fbe3c2c3c71"]}},"ed90d5c54eb545478a19ab6c6cda0a0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c7f8190cefe4394b05010bc4d894415":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a313136611ad4185832211e83947fc86","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":26421880,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":26421880,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2359b7868e9a403b933123b37877a365"}},"efbc5601c0ca4272aa2c7fbe3c2c3c71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_51cb74361de64f5a88f45802ba82a35a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 26422272/? [00:11&lt;00:00, 2353595.81it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72c5287f8d884b6f9211256981bba753"}},"a313136611ad4185832211e83947fc86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2359b7868e9a403b933123b37877a365":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51cb74361de64f5a88f45802ba82a35a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"72c5287f8d884b6f9211256981bba753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ea3655784ff47a282388366277cbfd9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8c1e4734cad74b909b6ae77e4393a0fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4731c852cca4332b77ed9a6d22a1d44","IPY_MODEL_fb4879ba4a4a48bb8b2d3baf954da7ba"]}},"8c1e4734cad74b909b6ae77e4393a0fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4731c852cca4332b77ed9a6d22a1d44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_12a78d95c95b406e8835fd8d37ce6d33","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":29515,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29515,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a2e1f172a22477bbb223a488aa5d36a"}},"fb4879ba4a4a48bb8b2d3baf954da7ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_72f415c9f2e2458784a97aec310addf4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:08&lt;00:00, 3309.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c38b8c39adc3481eae6f73455dbc77ea"}},"12a78d95c95b406e8835fd8d37ce6d33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4a2e1f172a22477bbb223a488aa5d36a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72f415c9f2e2458784a97aec310addf4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c38b8c39adc3481eae6f73455dbc77ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a60e5d6f31304747808773751f5759ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8b5fd552490d41728de8f120a9eab103","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f2695fde00cc4d83bf2f60fa85d3970f","IPY_MODEL_3231042cda1046cfa15eb468df682eed"]}},"8b5fd552490d41728de8f120a9eab103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2695fde00cc4d83bf2f60fa85d3970f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_39ad4291f2bc40e5a700e73fc55525c1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4422102,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4422102,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4810ddb3bc684b659ab56e1d1fb25be2"}},"3231042cda1046cfa15eb468df682eed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e50678e122554727aff40a760d1ec285","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4422656/? [00:01&lt;00:00, 2945661.84it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_49b5e71f30ca498da12fefaac4f14b73"}},"39ad4291f2bc40e5a700e73fc55525c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4810ddb3bc684b659ab56e1d1fb25be2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e50678e122554727aff40a760d1ec285":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"49b5e71f30ca498da12fefaac4f14b73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"694ff87b126647d4ad4327467997b76a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_244ebc1df0bf44f88ab56f8515a12cab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d2b570a8cf14c0791264471152183a7","IPY_MODEL_52002473459d49548a76f27136d9c828"]}},"244ebc1df0bf44f88ab56f8515a12cab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d2b570a8cf14c0791264471152183a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba799d85ee4d4cad9037862414da1675","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5148,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5148,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13ece15adf4740319c316c7964f39a0e"}},"52002473459d49548a76f27136d9c828":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2ddc568666244074a899ddba9560cafd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6144/? [00:00&lt;00:00, 19746.34it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f4caad7de0d34a3eafe2c6d2347df7e0"}},"ba799d85ee4d4cad9037862414da1675":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"13ece15adf4740319c316c7964f39a0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ddc568666244074a899ddba9560cafd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f4caad7de0d34a3eafe2c6d2347df7e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Pn7E8tXofBdm"},"source":["#Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaZdyOqH8ta1","executionInfo":{"status":"ok","timestamp":1618403845441,"user_tz":-300,"elapsed":7033,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"c5b6352b-a5fa-4e6e-9012-6b6176f450ac"},"source":["!pip install pkbar"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Collecting pkbar\n","  Downloading https://files.pythonhosted.org/packages/95/8f/28e0a21b27f836a8903315050db17dd68e55bf477b6fde52d1c68da3c8a6/pkbar-0.5-py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pkbar) (1.19.5)\n","Installing collected packages: pkbar\n","Successfully installed pkbar-0.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F0hq8_ykmK2J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617517043502,"user_tz":-300,"elapsed":42651,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"88c8cd28-f581-4e57-fb34-8c1a15b996a3"},"source":["\\from google.colab import drive\n","from google.colab import files\n","import sys\n","import time\n","\n","drive.mount('/content/gdrive/', force_remount=True)\n","root_dir = \"/content/gdrive/My Drive/\"\n","base_dir = root_dir + 'Colab Notebooks/MS Thesis/PSGD Paper/'\n","results_dir = base_dir + 'CNN/results_fashion/'\n","logs_dir = base_dir + 'log'\n","sys.path.append(base_dir)\n","import preconditioned_stochastic_gradient_descent as psgd \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aEZtit9cjlMG","executionInfo":{"status":"ok","timestamp":1618403853065,"user_tz":-300,"elapsed":7589,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["import matplotlib.pyplot as plt\n","import torch\n","from torch.autograd import grad\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import numpy as np\n","import time\n","import tqdm\n","import pkbar\n","import math\n","\n","from tabulate import tabulate\n","import scipy.io\n","from sklearn import metrics\n","import plotly.express as px\n","from torchsummary import summary\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"2D27oOpzYVaF","executionInfo":{"status":"ok","timestamp":1618404601956,"user_tz":-300,"elapsed":6269,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["torch.manual_seed(1)\n","\n","loss, accuracy = train_loss(data, target)\n","\n","grads = grad(loss, Ws, create_graph=True)\n","        \n","\n","v = [torch.randn(W.shape).to(device) for W in Ws]\n","Hv = grad(grads, Ws, v, retain_graph = True)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"extfjoX7bYY0","executionInfo":{"status":"ok","timestamp":1618404605371,"user_tz":-300,"elapsed":3283,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["grad(loss, Ws)"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8nsF9IHZ6Ob","executionInfo":{"status":"ok","timestamp":1618404267381,"user_tz":-300,"elapsed":2180,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"35486971-f6bd-4217-878c-84ccb742aa67"},"source":["Hv[0]"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 2.4155e-01,  1.2074e-01, -1.8860e-01, -3.9037e-01, -2.3329e-01,\n","          1.8804e-02],\n","        [-3.1767e-02, -2.3075e-01, -2.6723e-01, -3.5545e-01,  8.6497e-02,\n","          3.9386e-02],\n","        [-1.7787e-01, -3.0711e-01, -2.8066e-01, -7.4507e-04,  3.8544e-02,\n","         -1.9226e-01],\n","        [-3.8632e-01, -4.0677e-01, -3.8292e-02,  6.9345e-02, -3.1142e-01,\n","         -2.9080e-01],\n","        [-4.9954e-01, -2.5271e-01, -4.6380e-01, -7.0029e-01, -6.0185e-01,\n","         -5.7421e-01],\n","        [-2.2439e-01, -4.0243e-01, -5.6832e-01, -5.3006e-01, -4.8062e-01,\n","         -1.0052e-01],\n","        [-3.6651e-01, -6.2189e-01, -4.7695e-01, -3.8778e-01, -7.2405e-03,\n","         -3.5051e-01],\n","        [-6.7417e-01, -4.7869e-01, -5.5596e-01, -1.1177e-02, -3.2173e-01,\n","         -6.7865e-01],\n","        [-5.1307e-01, -5.7372e-01,  6.4551e-01,  6.0423e-01,  4.8638e-01,\n","          2.9199e-01],\n","        [ 9.9710e-02,  1.0967e+00,  8.8442e-01,  6.6170e-01,  3.8285e-01,\n","          2.6951e-01],\n","        [ 1.1537e+00,  8.9046e-01,  7.3349e-01,  5.2457e-01,  3.8726e-01,\n","          1.0278e+00],\n","        [ 8.9224e-01,  7.9927e-01,  5.7185e-01,  3.5541e-01,  1.1685e+00,\n","          8.6778e-01],\n","        [ 6.1015e-01,  5.6017e-01,  2.2899e-01, -1.0037e+00, -1.4681e+00,\n","         -1.1710e+00],\n","        [-1.1532e+00, -1.2618e+00, -1.0890e+00, -1.3607e+00, -1.0281e+00,\n","         -1.0295e+00],\n","        [-1.3122e+00, -1.1516e+00, -1.3843e+00, -1.1987e+00, -1.2638e+00,\n","         -1.4654e+00],\n","        [-1.2813e+00, -1.5457e+00, -1.2170e+00, -1.4600e+00, -1.6991e+00,\n","         -1.1752e+00],\n","        [-1.3800e+00, -1.2701e+00, -1.5720e+00, -1.7816e+00, -1.3766e-03,\n","          9.2510e-02],\n","        [ 4.6593e-02,  1.6247e-01, -1.8082e-02,  4.3221e-02,  3.8992e-02,\n","         -2.5440e-02],\n","        [ 1.3863e-01,  1.5536e-03,  3.8544e-02, -5.9383e-02, -9.9022e-02,\n","          7.1813e-02],\n","        [ 4.5802e-02,  1.1154e-03, -2.0689e-01, -1.4766e-01,  1.2103e-02,\n","         -1.3106e-02],\n","        [ 7.0442e-03, -1.6065e-01, -1.6643e-01, -1.2574e-02, -3.6792e-02,\n","          1.6540e-01],\n","        [ 3.5734e-02,  7.7230e-02,  5.4447e-03, -4.1252e-02,  4.2904e-02,\n","         -7.3643e-02],\n","        [ 1.3394e-01,  7.7342e-02,  6.8814e-02, -1.7305e-01,  4.7552e-03,\n","          8.1253e-02],\n","        [ 2.4331e-02,  6.1006e-02,  2.4726e-02, -1.4373e-02,  4.7932e-02,\n","         -4.1448e-02],\n","        [-1.0791e-01,  5.3679e-03, -5.3294e-03,  9.1736e-02, -6.5052e-02,\n","         -1.5208e-01],\n","        [-7.8940e-01, -1.1529e+00,  2.2165e+00, -2.1849e+00,  1.5271e-01,\n","          4.0055e-01]], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"VWej4ukgaYuu","executionInfo":{"status":"error","timestamp":1618404298268,"user_tz":-300,"elapsed":2540,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"ad2a7024-866a-43dd-8af6-830b625a24a5"},"source":["grad(loss, Ws)"],"execution_count":45,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-967f0bfb2923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."]}]},{"cell_type":"markdown","metadata":{"id":"QKooB49HfKzR"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"roPf15eMfNuJ","executionInfo":{"status":"ok","timestamp":1618403837426,"user_tz":-300,"elapsed":4303,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["def plot_loss_metrics(xaxis,yaxis,title, x_label,y_label):\n"," \n","  fig = go.Figure()\n","  i = 0\n","  if(xaxis != None):\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(x = xaxis[opt], y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","  else:\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","\n","  fig.update_layout(title=title, xaxis_title=x_label, yaxis_title=y_label, yaxis_type=\"log\")\n","  fig.show()\n","  fig.write_html(results_dir + title + \".html\")\n","\n","def plot_acc_metrics(xaxis,yaxis,title, x_label,y_label):\n"," \n","  fig = go.Figure()\n","  i = 0\n","  if(xaxis != None):\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(x = xaxis[opt], y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","  else:\n","    for opt in opts:\n","      fig.add_trace(go.Scatter(y=yaxis[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","      i = i + 1\n","\n","  fig.update_layout(title=title, xaxis_title=x_label, yaxis_title=y_label, yaxis=dict(range=[0.75, 1]))\n","  fig.show()\n","  fig.write_html(results_dir + title + \".html\")\n","\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ejKz-9nfUoy","executionInfo":{"status":"ok","timestamp":1618403837430,"user_tz":-300,"elapsed":4299,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["np.random.seed(0)\n","\n","# Parameter Settings\n","BATCH_SIZE = 64\n","test_BATCH_SIZE = 1000\n","EPOCHS = 20\n","GAP = 100"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t71vTNyumHao"},"source":["# Data Download"]},{"cell_type":"code","metadata":{"id":"LyioOEA_kdvB","colab":{"base_uri":"https://localhost:8080/","height":675,"referenced_widgets":["f59eb27e576b4722bfc8250a1d45aa08","ed90d5c54eb545478a19ab6c6cda0a0c","1c7f8190cefe4394b05010bc4d894415","efbc5601c0ca4272aa2c7fbe3c2c3c71","a313136611ad4185832211e83947fc86","2359b7868e9a403b933123b37877a365","51cb74361de64f5a88f45802ba82a35a","72c5287f8d884b6f9211256981bba753","8ea3655784ff47a282388366277cbfd9","8c1e4734cad74b909b6ae77e4393a0fb","b4731c852cca4332b77ed9a6d22a1d44","fb4879ba4a4a48bb8b2d3baf954da7ba","12a78d95c95b406e8835fd8d37ce6d33","4a2e1f172a22477bbb223a488aa5d36a","72f415c9f2e2458784a97aec310addf4","c38b8c39adc3481eae6f73455dbc77ea","a60e5d6f31304747808773751f5759ab","8b5fd552490d41728de8f120a9eab103","f2695fde00cc4d83bf2f60fa85d3970f","3231042cda1046cfa15eb468df682eed","39ad4291f2bc40e5a700e73fc55525c1","4810ddb3bc684b659ab56e1d1fb25be2","e50678e122554727aff40a760d1ec285","49b5e71f30ca498da12fefaac4f14b73","694ff87b126647d4ad4327467997b76a","244ebc1df0bf44f88ab56f8515a12cab","7d2b570a8cf14c0791264471152183a7","52002473459d49548a76f27136d9c828","ba799d85ee4d4cad9037862414da1675","13ece15adf4740319c316c7964f39a0e","2ddc568666244074a899ddba9560cafd","f4caad7de0d34a3eafe2c6d2347df7e0"]},"executionInfo":{"status":"ok","timestamp":1618403841382,"user_tz":-300,"elapsed":7919,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"5caa5f5c-a530-4915-d06a-edfbb0d6de8a"},"source":["train_loader = torch.utils.data.DataLoader(\n","        datasets.FashionMNIST('./data', train=True, download=True,           \n","                       transform=transforms.Compose([                       \n","                               transforms.ToTensor()])),    \n","                        batch_size=BATCH_SIZE, shuffle=True, num_workers = 4, pin_memory = True)\n","test_loader = torch.utils.data.DataLoader(    \n","        datasets.FashionMNIST('./data', train=False, transform=transforms.Compose([\n","                       transforms.ToTensor()])),    \n","                        batch_size=test_BATCH_SIZE, shuffle=True, num_workers=4, pin_memory = True)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f59eb27e576b4722bfc8250a1d45aa08","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=26421880.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ea3655784ff47a282388366277cbfd9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=29515.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a60e5d6f31304747808773751f5759ab","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4422102.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"694ff87b126647d4ad4327467997b76a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5148.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning:\n","\n","The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LAMhwYaRmbIF","executionInfo":{"status":"ok","timestamp":1618403841385,"user_tz":-300,"elapsed":7804,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["n_batches = np.ceil(len(train_loader.dataset)/BATCH_SIZE)\n","n_test_batches = np.ceil(len(test_loader.dataset)/test_BATCH_SIZE)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAJdx1Ga6xFX","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1618403841388,"user_tz":-300,"elapsed":7606,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"34ca94b4-3e7c-4bb4-de51-cf4ffb4be8ab"},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n","    print(\"Running on the GPU\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Running on the CPU\")\n","torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Running on the GPU\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"O55VB__slpJx"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"2N_7RpDVlbZE","executionInfo":{"status":"ok","timestamp":1618403853068,"user_tz":-300,"elapsed":7407,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["\"\"\"input image size for the original LeNet5 is 32x32, here is 28x28\"\"\"\n","torch.manual_seed(1)\n","torch.cuda.manual_seed_all(1)\n","def initialize_weights():\n","    W1 = torch.nn.init.xavier_uniform_((0.1*torch.randn(1*5*5+1,  6)).clone().detach().requires_grad_(True)).to(device)\n","    W2 = torch.nn.init.xavier_uniform_((0.1*torch.randn(6*5*5+1,  16)).clone().detach().requires_grad_(True)).to(device)\n","    W3 = torch.nn.init.xavier_uniform_((0.1*torch.randn(16*4*4+1, 120)).clone().detach().requires_grad_(True)).to(device)\n","    W4 = torch.nn.init.xavier_uniform_((0.1*torch.randn(120+1,    84)).clone().detach().requires_grad_(True)).to(device)\n","    W5 = torch.nn.init.xavier_uniform_((0.1*torch.randn(84+1,     10)).clone().detach().requires_grad_(True)).to(device)\n","    Ws = [W1, W2, W3, W4, W5]\n","    return Ws\n","\n","def LeNet5(x, return_all = False): \n","    W1, W2, W3, W4, W5 = Ws\n","    x1 = F.relu(F.conv2d(x, W1[:-1].view(6,1,5,5), bias=W1[-1]))\n","    x2 = F.max_pool2d(x1, 2)\n","    x3 = F.relu(F.conv2d(x2, W2[:-1].view(16,6,5,5), bias=W2[-1]))\n","    x4 = F.max_pool2d(x3, 2)\n","    x5 = F.relu(x4.view(-1, 16*4*4).mm(W3[:-1]) + W3[-1])\n","    x6 = F.relu(x5.mm(W4[:-1]) + W4[-1])\n","    # x = F.dropout(x, 0.3, training = True)\n","    y = x6.mm(W5[:-1]) + W5[-1]\n","    if return_all:\n","      return F.log_softmax(y, dim = 1), [x, x1, x2, x3, x4, x5, x6, y]\n","    return F.log_softmax(y, dim=1)\n"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1hOFi1DHlx2Q"},"source":["# Loss Function"]},{"cell_type":"code","metadata":{"id":"ttaD9mDElrR1","executionInfo":{"status":"ok","timestamp":1618403853070,"user_tz":-300,"elapsed":7080,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}}},"source":["def train_loss(data, target):\n","    y = LeNet5(data)\n","    loss = F.nll_loss(y, target)\n","    # loss = F.cross_entropy(y, target)\n","    _, max_indices = torch.max(y, dim = 1)\n","    accuracy = (max_indices == target).sum(dtype=torch.float32)/max_indices.size(0)\n","    return loss, accuracy\n","\n","def test_loss():\n","    loss = 0\n","    accuracy = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            y = LeNet5(data)\n","            loss += F.nll_loss(y, target)\n","            _, pred = torch.max(y, dim=1)\n","            accuracy += (pred == target).sum(dtype=torch.float32)/pred.size(0)\n","    return loss.item()/n_test_batches, accuracy.item()/n_test_batches\n","\n","def save_start_condition(trainlosslist, testlosslist,trainacclist, testacclist, timelist):\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      data, target = data.to(device), target.to(device)\n","      loss, accuracy = train_loss(data, target)\n","      trainloss += loss\n","      trainacc += accuracy\n","      \n","  \n","    timelist.append(0)\n","\n","    testloss, testacc = test_loss()\n","\n","    trainlosslist.append(trainloss.item()/n_batches)\n","    trainacclist.append(trainacc.item()/n_batches)\n","    testlosslist.append(testloss)\n","    testacclist.append(testacc)\n","    print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    .format(0, trainlosslist[-1], testlosslist[-1], trainacclist[-1], testacclist[-1],np.sum(timelist)))"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w5nub-2OIB1v"},"source":["# ALL TEST"]},{"cell_type":"markdown","metadata":{"id":"KHHRjmBv5nGy"},"source":["## SGD"]},{"cell_type":"code","metadata":{"id":"6-Kz6zZw5osv","colab":{"base_uri":"https://localhost:8080/","height":751},"executionInfo":{"status":"error","timestamp":1618403869228,"user_tz":-300,"elapsed":21209,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"405e4922-0cc1-442b-b507-836cb3a3b75a"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","        \n","        with torch.no_grad():\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*grads[i]\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    \n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'sgd.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":28,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4306401169376333; test loss: 2.4298145294189455, train_accuracy: 0.10022987739872068, test_accuracy:0.1004000186920166, time: 0\n","Epoch: 1/20\n","438/938 [=============>................] - ETA: 3s - loss: 0.7333 - acc: 0.7264"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8b7dbfa680>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt: \n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-7aa34834a9b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-1b18944101de>\u001b[0m in \u001b[0;36mtrain_loss\u001b[0;34m(data, target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# loss = F.cross_entropy(y, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-530f053abd92>\u001b[0m in \u001b[0;36mLeNet5\u001b[0;34m(x, return_all)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m# x = F.dropout(x, 0.3, training = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mW5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"dYV3Ro1nl9-w"},"source":["## Adam"]},{"cell_type":"code","metadata":{"id":"ShkQySPkl0jM","colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"status":"error","timestamp":1618404118249,"user_tz":-300,"elapsed":16398,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"9f2de241-d12a-4338-a88a-e05c42e4b7ad"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","\n","m0 = [torch.zeros(W.shape).to(device) for W in Ws]\n","v0 = [torch.zeros(W.shape).to(device) for W in Ws]\n","step_size = 0.005\n","cnt = 0\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","for epoch in range(EPOCHS):\n","    n = 0\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws)#, create_graph=True)\n","        trainloss += loss\n","        trainacc += accuracy\n","        \n","\n","        with torch.no_grad():\n","            lmbd = min(cnt/(cnt+1), 0.9)\n","            m0 = [lmbd*old + (1.0-lmbd)*new for (old, new) in zip(m0, grads)]\n","            lmbd = min(cnt/(cnt+1), 0.999)\n","            v0 = [lmbd*old + (1.0-lmbd)*new*new for (old, new) in zip(v0, grads)]\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_size*(m0[i]/torch.sqrt(v0[i] + 1e-8))\n","            cnt = cnt + 1\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1    \n","        \n","    t1 = time.time() - t0\n","    times.append(t1)\n","\n","    testloss, testacc = test_loss()\n","\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    # .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'adam.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":37,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4306401169376333; test loss: 2.4298145294189455, train_accuracy: 0.10022987739872068, test_accuracy:0.1004000186920166, time: 0\n","Epoch: 1/20\n","690/938 [=====================>........] - ETA: 1s - loss: 0.5272 - acc: 0.8044"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-7af4fb92a705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, create_graph=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtrainloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrainacc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"8AoYYDPCIMkn"},"source":["## Full Kronecker"]},{"cell_type":"code","metadata":{"id":"lRcCtC_omg8l","colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"status":"error","timestamp":1618404187615,"user_tz":-300,"elapsed":10646,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"988fd5cc-5929-477d-adbf-f7d6e4f5b12f"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","\n","        v = [torch.randn(W.shape).to(device) for W in Ws]\n","        Hv = grad(grads, Ws, v)\n","        \n","        with torch.no_grad():\n","            Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","            pre_grads = [psgd.precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    \n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'Kron.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":40,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4306401169376333; test loss: 2.4298145294189455, train_accuracy: 0.10022987739872068, test_accuracy:0.1004000186920166, time: 0\n","Epoch: 1/20\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-96f8e8cce318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mQs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpsgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_precond_kron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mpre_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpsgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecond_grad_kron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre_grads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-96f8e8cce318>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mQs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpsgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_precond_kron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mpre_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpsgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecond_grad_kron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpre_grads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'psgd' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"3XDQPC9p5vgk"},"source":["## DPSGD Approach 1"]},{"cell_type":"code","metadata":{"id":"m7A2qd5XHXzL"},"source":["_tiny = 1.2e-38 \n"," # pi = (torch.trace(Ql)*Qr.shape[0])/(torch.trace(Qr)*Ql.shape[0])\n","    # \n","\n","    \n","def precond_grad_kron(Ql, Qr, Grad):\n","    P1 = Ql.t().mm(Ql)\n","    P2 = Qr.t().mm(Qr)\n","    pi = (torch.trace(P1)*P2.shape[0])/(torch.trace(P2)*P1.shape[0])\n","    IL = torch.ones(P1.shape[0]).to(device)\n","    IR = (torch.ones(P2.shape[0])).to(device)\n","    P1 = P1 + torch.diag(torch.sqrt((pi)*(eta + lambd))*IL)\n","    P2 = P2 + torch.diag(torch.sqrt((1/pi)*(eta + lambd))*IR)\n","\n","    return P1.mm(Grad).mm(P2)\n","\n","def update_lambda(loss1, loss2, M, lambd, omega):\n","    \n","    r = abs(loss2 - loss1)/(M)\n","    # print(r, M, lambd)\n","    if r > 3/4:\n","      lambd = lambd*omega\n","    elif r < 1/4:\n","      lambd = lambd / omega\n","    return lambd\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L07W8H555y9S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616315057418,"user_tz":-300,"elapsed":1032402,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"0cae9cd5-2bb1-492c-caef-ee44fa07460a"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","lambd = 1\n","update_after = 5\n","omega = (19/20)**update_after\n","\n","eta = 1e-5\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    \n","    \n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","        if n % 1 == 0:\n","          v = [torch.randn(W.shape).to(device) for W in Ws]\n","          Hv = grad(grads, Ws, v)\n","        \n","        with torch.no_grad():\n","            Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","            pre_grads = [precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","\n","            if n % update_after == 0 and lambd > 1e-10:\n","                M = min([0.5*torch.dot(g.view(-1,), step_size*pg.view(-1,)) for (g, pg) in zip(grads, pre_grads)])\n","                # M = 0.5*sum([torch.sum(g*pg) for (g, pg) in zip(grads, pre_grads)])\n","                # M = 0.5*sum([torch.sum(-step_size * pg*psgd.precond_grad_kron(q[0], q[1], -step_size * pg)) \\\n","                #              for (g, pg, q) in zip(grads, pre_grads, Qs)])\n","                loss2 = F.nll_loss(LeNet5(data), target)\n","                loss1 = loss\n","                lambd = update_lambda(loss1, loss2, M,  lambd, omega)\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","\n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'Kron_damped.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4306401169376333; test loss: 2.4298145294189455, train_accuracy: 0.10022987739872068, test_accuracy:0.1004000186920166, time: 0\n","Epoch: 1/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.4835 - acc: 0.8203 - val_loss: 0.4164 - val_acc: 0.8450\n","Epoch: 2/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.2795 - acc: 0.8941 - val_loss: 0.3237 - val_acc: 0.8801\n","Epoch: 3/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.2136 - acc: 0.9191 - val_loss: 0.2892 - val_acc: 0.8930\n","Epoch: 4/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.1676 - acc: 0.9369 - val_loss: 0.2983 - val_acc: 0.8941\n","Epoch: 5/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.1385 - acc: 0.9492 - val_loss: 0.2949 - val_acc: 0.9006\n","Epoch: 6/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.1210 - acc: 0.9560 - val_loss: 0.3004 - val_acc: 0.9017\n","Epoch: 7/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.1101 - acc: 0.9606 - val_loss: 0.3083 - val_acc: 0.9022\n","Epoch: 8/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.1038 - acc: 0.9638 - val_loss: 0.3120 - val_acc: 0.9024\n","Epoch: 9/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.1002 - acc: 0.9654 - val_loss: 0.3142 - val_acc: 0.9015\n","Epoch: 10/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.0980 - acc: 0.9663 - val_loss: 0.3152 - val_acc: 0.9016\n","Epoch: 11/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.0966 - acc: 0.9667 - val_loss: 0.3164 - val_acc: 0.9020\n","Epoch: 12/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.0959 - acc: 0.9669 - val_loss: 0.3169 - val_acc: 0.9016\n","Epoch: 13/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.0954 - acc: 0.9671 - val_loss: 0.3173 - val_acc: 0.9017\n","Epoch: 14/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.0952 - acc: 0.9673 - val_loss: 0.3175 - val_acc: 0.9020\n","Epoch: 15/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.0950 - acc: 0.9672 - val_loss: 0.3176 - val_acc: 0.9020\n","Epoch: 16/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.0950 - acc: 0.9673 - val_loss: 0.3177 - val_acc: 0.9019\n","Epoch: 17/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.0948 - acc: 0.9674 - val_loss: 0.3177 - val_acc: 0.9020\n","Epoch: 18/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.0947 - acc: 0.9674 - val_loss: 0.3178 - val_acc: 0.9021\n","Epoch: 19/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.0947 - acc: 0.9675 - val_loss: 0.3178 - val_acc: 0.9021\n","Epoch: 20/20\n","938/938 [==============================] - 18s 19ms/step - loss: 0.0947 - acc: 0.9675 - val_loss: 0.3178 - val_acc: 0.9021\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3oq1QQCPEdZh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616315065584,"user_tz":-300,"elapsed":1040552,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"203dafd7-f3bd-4215-874f-e786fcd1c793"},"source":["full_data, full_target = [],[]\n","for batch_idx, (data, target) in enumerate(train_loader):\n","      data, target = data, target\n","      full_data.extend(data)\n","      full_target.extend(data)\n","full_data = torch.stack(full_data).to(device)\n","full_target = torch.stack(full_target)#.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-qIgKzzS1i7w"},"source":["# torch.manual_seed(1)\n","# Ws = initialize_weights()\n","# Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","# dQs = [[torch.ones(W.shape[0],1).to(device), torch.ones(1,W.shape[1]).to(device)] for W in Ws]\n","\n","# step_size = 0.1\n","# grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","# TrainLoss, TestLoss = [], []\n","# TrainAcc, TestAcc = [], []\n","# times = []\n","# save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","# full_pre_grads = [torch.zeros(W.shape).to(device) for W in Ws]\n","# lambd = 1\n","# update_after = 5\n","# omega = (19/20)**update_after\n","\n","# eta = 1e-5\n","# for epoch in range(EPOCHS):\n","#     kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","#     trainloss = 0.0\n","#     trainacc = 0.0\n","#     n = 0\n","#     t0 = time.time()\n","#     loss, accuracy = train_loss(full_data, fulltarget)\n","#     grads = grad(trainloss, Ws, create_graph=True)\n","#     v = [torch.randn(W.shape).to(device) for W in Ws]\n","#     Hv = grad(grads, Ws, v)\n","#     with torch.no_grad():\n","#         Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","#         full_pre_grads = [psgd.precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","      \n","\n","    \n","#     for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","#         data, target = data.to(device), target.to(device)\n","#         loss, accuracy = train_loss(data, target)\n","        \n","#         grads = grad(loss, Ws, create_graph=True)\n","        \n","#         trainloss += loss\n","#         trainacc += accuracy          \n","        \n","#         with torch.no_grad():\n","#             Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","#             pre_grads = [psgd.precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","#             damp_grads = [((lambd+eta)**0.5)*g for g in grads]\n","#             pre_grads = [pg+dg for (pg, dg) in zip(pre_grads, damp_grads)] \n","#             grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","#             step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","\n","#             for i in range(len(Ws)):\n","#                 Ws[i] -= step_adjust*step_size*(pre_grads[i] - full_pre_grads[i])\n","\n","#             if n % update_after == 0 and lambd > 1e-10:\n","#                 M = min([0.5*torch.dot(g.view(-1,), step_size*pg.view(-1,)) for (g, pg) in zip(grads, pre_grads)])\n","#                 # M = 0.5*sum([torch.sum(g*pg) for (g, pg) in zip(grads, pre_grads)])\n","#                 # M = 0.5*sum([torch.sum(-step_size * pg*psgd.precond_grad_kron(q[0], q[1], -step_size * pg)) \\\n","#                 #              for (g, pg, q) in zip(grads, pre_grads, Qs)])\n","#                 loss2 = F.nll_loss(LeNet5(data), target)\n","#                 loss1 = loss\n","#                 lambd = update_lambda(loss1, loss2, M,  lambd, omega)\n","\n","#         kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","#         n += 1\n","\n","#     t1 = time.time() - t0\n","#     times.append(t1)\n","#     TrainLoss.append(trainloss.item()/n_batches)\n","#     TrainAcc.append(trainacc.item()/n_batches)\n","\n","#     testloss, testacc = test_loss()\n","\n","#     TestLoss.append(testloss)\n","#     TestAcc.append(testacc)\n","#     kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","#     step_size = 0.01**(1/9)*step_size\n","#     # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","#     #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","# # scipy.io.savemat(results_dir + 'Kron_damped.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qzn9JO8JGH7m"},"source":["## DPSGD Approach 2"]},{"cell_type":"code","metadata":{"id":"l5ivNBPX8_Qv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616315644786,"user_tz":-300,"elapsed":346239,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"f1aef110-9411-45cb-d416-fcf93b733a04"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","dQs = [[torch.ones(W.shape[0],1).to(device), torch.ones(1,W.shape[1]).to(device)] for W in Ws]\n","\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","lambd = 1\n","update_after = 5\n","omega = (19/20)**update_after\n","\n","eta = 1e-5\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    \n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","        if n % 1 == 0:\n","          v = [torch.randn(W.shape).to(device) for W in Ws]\n","          Hv = grad(grads, Ws, v)\n","        \n","        with torch.no_grad():\n","            Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","            pre_grads = [psgd.precond_grad_kron(q[0], q[1], g) for (q, g) in zip(Qs, grads)]\n","            damp_grads = [((lambd+eta)**0.5)*g for g in grads]\n","            pre_grads = [pg+dg for (pg, dg) in zip(pre_grads, damp_grads)] \n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","\n","            if n % update_after == 0 and lambd > 1e-10:\n","                M = min([0.5*torch.dot(g.view(-1,), step_size*pg.view(-1,)) for (g, pg) in zip(grads, pre_grads)])\n","                # M = 0.5*sum([torch.sum(g*pg) for (g, pg) in zip(grads, pre_grads)])\n","                # M = 0.5*sum([torch.sum(-step_size * pg*psgd.precond_grad_kron(q[0], q[1], -step_size * pg)) \\\n","                #              for (g, pg, q) in zip(grads, pre_grads, Qs)])\n","                loss2 = F.nll_loss(LeNet5(data), target)\n","                loss1 = loss\n","                lambd = update_lambda(loss1, loss2, M,  lambd, omega)\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","\n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'Kron_damped2.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4306401169376333; test loss: 2.4298145294189455, train_accuracy: 0.10022987739872068, test_accuracy:0.1004000186920166, time: 0\n","Epoch: 1/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.4691 - acc: 0.8291 - val_loss: 0.3893 - val_acc: 0.8508\n","Epoch: 2/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.2822 - acc: 0.8955 - val_loss: 0.3207 - val_acc: 0.8844\n","Epoch: 3/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.2137 - acc: 0.9204 - val_loss: 0.2894 - val_acc: 0.8955\n","Epoch: 4/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.1665 - acc: 0.9382 - val_loss: 0.2848 - val_acc: 0.9019\n","Epoch: 5/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.1367 - acc: 0.9498 - val_loss: 0.2906 - val_acc: 0.9056\n","Epoch: 6/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.1195 - acc: 0.9571 - val_loss: 0.2969 - val_acc: 0.9063\n","Epoch: 7/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.1087 - acc: 0.9621 - val_loss: 0.3031 - val_acc: 0.9059\n","Epoch: 8/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.1028 - acc: 0.9640 - val_loss: 0.3069 - val_acc: 0.9054\n","Epoch: 9/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0992 - acc: 0.9653 - val_loss: 0.3099 - val_acc: 0.9038\n","Epoch: 10/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0972 - acc: 0.9661 - val_loss: 0.3107 - val_acc: 0.9032\n","Epoch: 11/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0957 - acc: 0.9669 - val_loss: 0.3120 - val_acc: 0.9038\n","Epoch: 12/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0950 - acc: 0.9671 - val_loss: 0.3126 - val_acc: 0.9034\n","Epoch: 13/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0946 - acc: 0.9675 - val_loss: 0.3130 - val_acc: 0.9036\n","Epoch: 14/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0943 - acc: 0.9676 - val_loss: 0.3132 - val_acc: 0.9034\n","Epoch: 15/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0941 - acc: 0.9677 - val_loss: 0.3133 - val_acc: 0.9034\n","Epoch: 16/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0941 - acc: 0.9676 - val_loss: 0.3134 - val_acc: 0.9034\n","Epoch: 17/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0939 - acc: 0.9677 - val_loss: 0.3135 - val_acc: 0.9034\n","Epoch: 18/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0939 - acc: 0.9677 - val_loss: 0.3135 - val_acc: 0.9034\n","Epoch: 19/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0938 - acc: 0.9677 - val_loss: 0.3135 - val_acc: 0.9034\n","Epoch: 20/20\n","938/938 [==============================] - 17s 18ms/step - loss: 0.0939 - acc: 0.9677 - val_loss: 0.3135 - val_acc: 0.9034\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pzF0kQ3g7Bb0"},"source":["## D-PDSGD w/ momentum"]},{"cell_type":"code","metadata":{"id":"OM3_pW06XRPM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"76b2bbd6-022f-4d62-a0c2-5d4935f91e0f"},"source":["def precond_kron(Ql, Qr, Pl, Pr, beta):\n","    P1 = Ql.t().mm(Ql)\n","    P2 = Qr.t().mm(Qr)\n","    pi = (torch.trace(P1)*P2.shape[0])/(torch.trace(P2)*P1.shape[0])\n","    IL = torch.ones(P1.shape[0]).to(device)\n","    IR = (torch.ones(P2.shape[0])).to(device)\n","    P1 = P1 + torch.diag(torch.sqrt((pi)*(eta + lambd))*IL)\n","    P2 = P2 + torch.diag(torch.sqrt((1/pi)*(eta + lambd))*IR)\n","\n","    Pl = beta*Pl + (1-beta)*P1 \n","    Pr = beta*Pr + (1-beta)*P2 \n","\n","    return [P1, P2, Pl, Pr]\n","\n","def precond_kron2(Ql, Qr, Pl, Pr, beta):\n","    P1 = Ql.t().mm(Ql)\n","    P2 = Qr.t().mm(Qr)\n","    Pl = beta*Pl + (1-beta)*P1 \n","    Pr = beta*Pr + (1-beta)*P2 \n","    return [P1, P2, Pl, Pr]\n","\n","def precond_grad_kron2(Pl, Pr, Grad):\n","    return Pl.mm(Grad).mm(Pr)\n","\n","torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","Ps = [[torch.zeros(W.shape[0]).to(device), torch.zeros(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","lambd = 1\n","update_after = 5\n","omega = (19/20)**update_after\n","eta = 1e-5\n","beta = 0.7\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    n = 0\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    t0 = time.time()\n","   \n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","\n","        v = [torch.randn(W.shape).to(device) for W in Ws]\n","        Hv = grad(grads, Ws, v)\n","        with torch.no_grad():\n","            Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","            beta = min(n/(n+1), 0.7)\n","            Ps = [precond_kron(q[0], q[1], p[0], p[1], beta) for (q, p) in zip(Qs, Ps)]\n","            pre_grads = [precond_grad_kron2(p[2], p[3], g) for (p, g) in zip(Ps, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","            if n % update_after == 0 and lambd > 1e-10:\n","                M = min([0.5*torch.dot(g.view(-1,), step_size*pg.view(-1,)) for (g, pg) in zip(grads, pre_grads)])\n","                loss2 = F.nll_loss(LeNet5(data), target)\n","                loss1 = loss\n","                lambd = update_lambda(loss1, loss2, M, lambd, omega)\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","\n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","# scipy.io.savemat(results_dir + 'mod_psgd1.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})\n","scipy.io.savemat(results_dir + 'new_psgd.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4306401169376333; test loss: 2.4298145294189455, train_accuracy: 0.10022987739872068, test_accuracy:0.1004000186920166, time: 0\n","Epoch: 1/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.4801 - acc: 0.8216 - val_loss: 0.4119 - val_acc: 0.8431\n","Epoch: 2/20\n","938/938 [==============================] - 19s 20ms/step - loss: 0.2816 - acc: 0.8948 - val_loss: 0.3313 - val_acc: 0.8789\n","Epoch: 3/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.2139 - acc: 0.9189 - val_loss: 0.3025 - val_acc: 0.8890\n","Epoch: 4/20\n","938/938 [==============================] - 18s 20ms/step - loss: 0.1675 - acc: 0.9366 - val_loss: 0.3125 - val_acc: 0.8936\n","Epoch: 5/20\n","938/938 [==============================] - 19s 20ms/step - loss: 0.1374 - acc: 0.9497 - val_loss: 0.3139 - val_acc: 0.8952\n","Epoch: 6/20\n"," 54/938 [>.............................] - ETA: 20s - loss: 0.1090 - acc: 0.9595       "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cinUCqTdicw2"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[torch.eye(W.shape[0]).to(device), torch.eye(W.shape[1]).to(device)] for W in Ws]\n","dQs = [[torch.ones(W.shape[0],1).to(device), torch.ones(1,W.shape[1]).to(device)] for W in Ws]\n","\n","step_size = 0.1\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","lambd = 1\n","update_after = 5\n","omega = (19/20)**update_after\n","beta = 0.7\n","eta = 1e-5\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    \n","    for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","        if n % 1 == 0:\n","          v = [torch.randn(W.shape).to(device) for W in Ws]\n","          Hv = grad(grads, Ws, v)\n","        \n","        with torch.no_grad():\n","            Qs = [psgd.update_precond_kron(q[0], q[1], dw, dg) for (q, dw, dg) in zip(Qs, v, Hv)]\n","            # beta = min(n/(n+1), 0.9)\n","            Ps = [precond_kron(q[0], q[1], p[0], p[1], beta) for (q, p) in zip(Qs, Ps)]\n","            pre_grads = [precond_grad_kron2(p[2], p[3], g) for (p, g) in zip(Ps, grads)]\n","            damp_grads = [((lambd+eta)**0.5)*g for g in grads]\n","            pre_grads = [pg+dg for (pg, dg) in zip(pre_grads, damp_grads)] \n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","\n","            if n % update_after == 0 and lambd > 1e-10:\n","                M = min([0.5*torch.dot(g.view(-1,), step_size*pg.view(-1,)) for (g, pg) in zip(grads, pre_grads)])\n","                # M = 0.5*sum([torch.sum(g*pg) for (g, pg) in zip(grads, pre_grads)])\n","                # M = 0.5*sum([torch.sum(-step_size * pg*psgd.precond_grad_kron(q[0], q[1], -step_size * pg)) \\\n","                #              for (g, pg, q) in zip(grads, pre_grads, Qs)])\n","                loss2 = F.nll_loss(LeNet5(data), target)\n","                loss1 = loss\n","                lambd = update_lambda(loss1, loss2, M,  lambd, omega)\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","\n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.01**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'mod_psgd2.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yj22SVg7tVwA"},"source":["##KFAC"]},{"cell_type":"code","metadata":{"id":"gNvGRjQ5tdt2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616318112504,"user_tz":-300,"elapsed":256095,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"56fe4bb5-204f-4808-c770-8d57dca06d72"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","from kfac import KFAC\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class LeNet5_K(nn.Module):\n","    def __init__(self):\n","        super(LeNet5_K, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n","        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n","        self.fc1 = nn.Linear(256, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(-1, 256)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return F.log_softmax(x, dim=1)\n","\n","def test_loss_K(model):\n","    model.eval()\n","    loss = 0\n","    accuracy = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            y = model(data)\n","            loss += F.nll_loss(y, target)\n","            _, pred = torch.max(y, dim=1)\n","            accuracy += (pred == target).sum(dtype=torch.float32)/pred.size(0)\n","    return loss.item()/n_test_batches, accuracy/n_test_batches\n","\n","model = LeNet5_K().to(device)\n","preconditioner = KFAC(model, 0.001, alpha=0.05, sua = True)\n","lr0 = 0.01\n","optimizer = optim.SGD(model.parameters(), lr=lr0)\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    model.train()\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        \n","        loss = F.nll_loss(output, target)\n","        _, max_ind = torch.max(output, dim = 1)\n","        accuracy = (max_ind == target).sum(dtype=torch.float32)/max_ind.size(0) \n","\n","        trainloss += loss\n","        trainacc += accuracy\n","\n","        loss.backward()\n","        preconditioner.step()\n","        optimizer.step()\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","        \n","    t1 = time.time() - t0\n","    times.append(t1)\n","\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    \n","    \n","    lr0 = 0.01**(1/9)*lr0\n","    optimizer.param_groups[0]['lr'] = lr0\n","    testloss, testacc = test_loss_K(model)\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch+1, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'KFAC.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4305425127432034; test loss: 2.429814910888672, train_accuracy: 0.10026319296375266, test_accuracy:0.10040000677108765, time: 0\n","Epoch: 1/20\n","  0/938 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.0000e+00"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n","\n","Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["938/938 [==============================] - 12s 13ms/step - loss: 0.4162 - acc: 0.8475 - val_loss: 0.3363 - val_acc: 0.8751\n","Epoch: 2/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.2718 - acc: 0.9002 - val_loss: 0.3077 - val_acc: 0.8842\n","Epoch: 3/20\n","938/938 [==============================] - 13s 14ms/step - loss: 0.2204 - acc: 0.9175 - val_loss: 0.2923 - val_acc: 0.8936\n","Epoch: 4/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1865 - acc: 0.9321 - val_loss: 0.2926 - val_acc: 0.8971\n","Epoch: 5/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1648 - acc: 0.9401 - val_loss: 0.2938 - val_acc: 0.8959\n","Epoch: 6/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1510 - acc: 0.9462 - val_loss: 0.2967 - val_acc: 0.8976\n","Epoch: 7/20\n","938/938 [==============================] - 13s 13ms/step - loss: 0.1420 - acc: 0.9502 - val_loss: 0.2994 - val_acc: 0.8991\n","Epoch: 8/20\n","938/938 [==============================] - 13s 13ms/step - loss: 0.1367 - acc: 0.9527 - val_loss: 0.3007 - val_acc: 0.8980\n","Epoch: 9/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1332 - acc: 0.9537 - val_loss: 0.3014 - val_acc: 0.8988\n","Epoch: 10/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1312 - acc: 0.9545 - val_loss: 0.3020 - val_acc: 0.8981\n","Epoch: 11/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1302 - acc: 0.9553 - val_loss: 0.3026 - val_acc: 0.8977\n","Epoch: 12/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1294 - acc: 0.9557 - val_loss: 0.3029 - val_acc: 0.8984\n","Epoch: 13/20\n","938/938 [==============================] - 13s 13ms/step - loss: 0.1289 - acc: 0.9559 - val_loss: 0.3031 - val_acc: 0.8980\n","Epoch: 14/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1285 - acc: 0.9559 - val_loss: 0.3032 - val_acc: 0.8980\n","Epoch: 15/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1285 - acc: 0.9560 - val_loss: 0.3032 - val_acc: 0.8978\n","Epoch: 16/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1285 - acc: 0.9560 - val_loss: 0.3032 - val_acc: 0.8979\n","Epoch: 17/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1284 - acc: 0.9560 - val_loss: 0.3033 - val_acc: 0.8979\n","Epoch: 18/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1285 - acc: 0.9560 - val_loss: 0.3033 - val_acc: 0.8979\n","Epoch: 19/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1283 - acc: 0.9561 - val_loss: 0.3033 - val_acc: 0.8979\n","Epoch: 20/20\n","938/938 [==============================] - 12s 13ms/step - loss: 0.1284 - acc: 0.9560 - val_loss: 0.3033 - val_acc: 0.8979\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MAHbvA_Eok-z"},"source":["## Shampoo"]},{"cell_type":"code","metadata":{"id":"ZBgeK5ttAmxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616318561205,"user_tz":-300,"elapsed":513639,"user":{"displayName":"M. USMAN QADEER","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDXrG0czXthVd59pFBGcQk02u209YXTh4NDJXhZA=s64","userId":"17493752484024501639"}},"outputId":"ab230a11-af39-4cc6-9ccb-883bc4af38e1"},"source":["torch.manual_seed(1)\n","Ws = initialize_weights()\n","Qs = [[0.01*torch.eye(W.shape[0]).to(device), 0.01*torch.eye(W.shape[1]).to(device)] for W in Ws]\n","step_size = 0.5\n","grad_norm_clip_thr = 0.1*sum(W.shape[0]*W.shape[1] for W in Ws)**0.5\n","TrainLoss, TestLoss = [], []\n","TrainAcc, TestAcc = [], []\n","times = []\n","save_start_condition(TrainLoss, TestLoss, TrainAcc, TestAcc, times)\n","\n","def matrix_power(matrix, power):\n","    # use CPU for svd for speed up\n","    matrix = matrix.cpu()\n","    u, s, v = torch.svd(matrix)\n","    return (u @ s.pow_(power).diag() @ v.t()).cuda()\n","\n","for epoch in range(EPOCHS):\n","    kbar = pkbar.Kbar(target=n_batches, epoch=epoch, num_epochs=EPOCHS, width=30, always_stateful=False, interval = 1)\n","    trainloss = 0.0\n","    trainacc = 0.0\n","    n = 0\n","    t0 = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        \n","      \n","        data, target = data.to(device), target.to(device)\n","        loss, accuracy = train_loss(data, target)\n","        \n","        grads = grad(loss, Ws, create_graph=True)\n","        \n","        trainloss += loss\n","        trainacc += accuracy\n","        \n","        with torch.no_grad():\n","            Qs = [[q[0] + g.mm(g.t()), q[1] + (g.t()).mm(g)] for (q, g) in zip(Qs, grads)]\n","            inv_Qs = [[matrix_power(q[0], -1/4), matrix_power(q[1], -1/4)]for q in Qs]\n","            pre_grads = [q[0].mm(g).mm(q[1]) for (q, g) in zip(inv_Qs, grads)]\n","            grad_norm = torch.sqrt(sum([torch.sum(g*g) for g in pre_grads]))\n","            step_adjust = min(grad_norm_clip_thr/(grad_norm + 1.2e-38), 1.0)\n","            for i in range(len(Ws)):\n","                Ws[i] -= step_adjust*step_size*pre_grads[i]\n","\n","        kbar.update(n, values=[(\"loss\", loss.item()), (\"acc\", accuracy.item())])\n","        n += 1\n","\n","    t1 = time.time() - t0\n","    times.append(t1)\n","    TrainLoss.append(trainloss.item()/n_batches)\n","    TrainAcc.append(trainacc.item()/n_batches)\n","    \n","    testloss, testacc = test_loss()\n","\n","    TestLoss.append(testloss)\n","    TestAcc.append(testacc)\n","    kbar.add(1, values=[(\"val_loss\", testloss), (\"val_acc\", testacc)])\n","    step_size = 0.1**(1/9)*step_size\n","    # print('Epoch: {}; train loss: {}; test loss: {}, train_accuracy: {}, test_accuracy:{}, time: {}'\\\n","    #  .format(epoch, TrainLoss[-1], TestLoss[-1], TrainAcc[-1], TestAcc[-1],np.sum(times)))\n","\n","scipy.io.savemat(results_dir + 'shampoo.mat', {'TrainLoss': TrainLoss, 'TestLoss': TestLoss, 'TrainAccuracy': TrainAcc,'TestAccuracy': TestAcc, 'Time':times})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning:\n","\n","This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 0; train loss: 2.4306401169376333; test loss: 2.4298145294189455, train_accuracy: 0.10022987739872068, test_accuracy:0.1004000186920166, time: 0\n","Epoch: 1/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.4525 - acc: 0.8305 - val_loss: 0.3641 - val_acc: 0.8678\n","Epoch: 2/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.2987 - acc: 0.8873 - val_loss: 0.3181 - val_acc: 0.8825\n","Epoch: 3/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.2575 - acc: 0.9029 - val_loss: 0.3088 - val_acc: 0.8873\n","Epoch: 4/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.2348 - acc: 0.9122 - val_loss: 0.3047 - val_acc: 0.8888\n","Epoch: 5/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.2183 - acc: 0.9191 - val_loss: 0.2977 - val_acc: 0.8926\n","Epoch: 6/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.2063 - acc: 0.9234 - val_loss: 0.2919 - val_acc: 0.8955\n","Epoch: 7/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.1982 - acc: 0.9257 - val_loss: 0.2921 - val_acc: 0.8963\n","Epoch: 8/20\n","938/938 [==============================] - 22s 23ms/step - loss: 0.1918 - acc: 0.9285 - val_loss: 0.2939 - val_acc: 0.8964\n","Epoch: 9/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.1873 - acc: 0.9300 - val_loss: 0.2934 - val_acc: 0.8978\n","Epoch: 10/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.1843 - acc: 0.9315 - val_loss: 0.2933 - val_acc: 0.8977\n","Epoch: 11/20\n","938/938 [==============================] - 22s 23ms/step - loss: 0.1817 - acc: 0.9326 - val_loss: 0.2929 - val_acc: 0.8985\n","Epoch: 12/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.1799 - acc: 0.9330 - val_loss: 0.2935 - val_acc: 0.8979\n","Epoch: 13/20\n","938/938 [==============================] - 22s 23ms/step - loss: 0.1787 - acc: 0.9337 - val_loss: 0.2939 - val_acc: 0.8971\n","Epoch: 14/20\n","938/938 [==============================] - 22s 23ms/step - loss: 0.1775 - acc: 0.9340 - val_loss: 0.2942 - val_acc: 0.8978\n","Epoch: 15/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.1769 - acc: 0.9344 - val_loss: 0.2941 - val_acc: 0.8970\n","Epoch: 16/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.1761 - acc: 0.9346 - val_loss: 0.2943 - val_acc: 0.8976\n","Epoch: 17/20\n","938/938 [==============================] - 22s 23ms/step - loss: 0.1760 - acc: 0.9347 - val_loss: 0.2943 - val_acc: 0.8975\n","Epoch: 18/20\n","938/938 [==============================] - 22s 23ms/step - loss: 0.1756 - acc: 0.9346 - val_loss: 0.2944 - val_acc: 0.8979\n","Epoch: 19/20\n","938/938 [==============================] - 22s 23ms/step - loss: 0.1753 - acc: 0.9350 - val_loss: 0.2945 - val_acc: 0.8973\n","Epoch: 20/20\n","938/938 [==============================] - 22s 24ms/step - loss: 0.1751 - acc: 0.9350 - val_loss: 0.2945 - val_acc: 0.8978\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VKqHDHWs7rPo"},"source":["# Comparison"]},{"cell_type":"code","metadata":{"id":"2sNOWNfay0sr"},"source":["opts = ['sgd','adam','KFAC', 'shampoo','Kron','Kron_damped', 'SAMDPSGD']\n","\n","total_train_time = {}\n","opts_data = {}\n","times = {}\n","train_times = {}\n","test_times = {}\n","train_losses = {}\n","test_losses = {}\n","train_accs = {}\n","test_accs = {}\n","train_err={}\n","test_err = {}\n","\n","\n","for opt in opts:\n","\topts_data[opt] = scipy.io.loadmat(results_dir+opt+'.mat')\t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gIYMFyL-C8d"},"source":["colors = ['#0000FF','#00FF00','#FF0000','#33F0FF','#FFA833','#000000','#33E0FF', '#FF33E6','#D433FF','#888A0B','#8A0B1E','#B498DF','#1B786D']\n","# colors = ['#0000FF','#00FF00','#FF0000','#33F0FF','#FFA833','#FFF933','#000000','#33E0FF','#FF33E6','#D433FF','#888A0B','#8A0B1E','#B498DF','#1B786D']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Rez_eVv8XdP"},"source":["for opt in opts:\n","  # print(opt)\n","  data = opts_data[opt]\n","  times[opt] = data.get('Time')\n","  train_times[opt] = np.cumsum(times[opt])\n","  test_times[opt] = np.cumsum(times[opt])\n","  total_train_time[opt] = np.sum(times[opt])\n","  train_losses[opt] = data.get('TrainLoss').reshape(EPOCHS+1,)\n","  train_accs[opt] = data.get('TrainAccuracy').reshape(EPOCHS+1,)\n","  test_losses[opt] = data.get('TestLoss').reshape(EPOCHS+1,)\n","  test_accs[opt] = data.get('TestAccuracy').reshape(EPOCHS+1)\n","  train_err[opt] = (1-data.get('TrainAccuracy')).reshape(EPOCHS+1,)\n","  \n","\n","for opt in ['kron_damped','SAMDPSGD']:\n","  test_err[opt] = (1-opts_data[opt].get('TestAccuracy')).reshape(EPOCHS+1,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyfJY86HUfT0"},"source":["\n","fig = go.Figure()\n","i = 0\n","for opt in ['kron', 'kron_damped','SAMDPSGD']:\n","  fig.add_trace(go.Scatter(y=test_err[opt], name = opt, mode='lines', line = dict(color = colors[i])))\n","  i = i + 1\n","\n","fig.update_layout(title='test error', xaxis_title='epochs', yaxis_title='test error', yaxis_type=\"log\")\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOGytOmR8w3V"},"source":["# plot train_losses vs Iterations\n","plot_loss_metrics(None,train_losses,'Train Loss vs EPOCHS', 'EPOCHS','Train Loss')\n","# plot test_losses vs Iterations\n","plot_loss_metrics(None,test_losses,'Test Loss vs EPOCHS', 'EPOCHS','Test Loss')\n","# # plot test_losses vs Iterations\n","plot_loss_metrics(train_times,train_losses,'Train Loss vs Time', 'Time','Train Loss')\n","# plot test_losses vs Iterations\n","plot_loss_metrics(test_times,test_losses,'Test Loss vs Time', 'Time','Test Loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKKKAIyTUDue"},"source":["# plot train_losses vs Iterations\n","plot_loss_metrics(None,train_err,'Train Loss vs EPOCHS', 'EPOCHS','Train Loss')\n","# plot test_losses vs Iterations\n","# plot_loss_metrics(None,test_losses,'Test Loss vs EPOCHS', 'EPOCHS','Test Loss')\n","# # plot test_losses vs Iterations\n","plot_loss_metrics(train_times,train_err,'Train Loss vs Time', 'Time','Train Loss')\n","# plot test_losses vs Iterations\n","# plot_loss_metrics(test_times,test_losses,'Test Loss vs Time', 'Time','Test Loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5R9mvQkv5DU"},"source":["# plot train_losses vs Iterations\n","plot_acc_metrics(None,train_accs,'Train Accuracy vs EPOCHS', 'EPOCHS','Train Accuracy')\n","# plot test_losses vs Iterations\n","plot_acc_metrics(None,test_accs,'Test Accuracy vs EPOCHS', 'EPOCHS','Test Accuracys')\n","# # plot test_losses vs Iterations\n","plot_acc_metrics(train_times,train_accs,'Train Accuracy vs Time', 'Time','Train Accuracy')\n","# plot test_losses vs Iterations\n","plot_acc_metrics(test_times,test_accs,'Test Accuracy vs Time', 'Time','Test Accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1emXQ9-RLkxg"},"source":[""],"execution_count":null,"outputs":[]}]}